{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Summarization Using KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values below can be treated as input parameters. They represent the following:\n",
    "- sampling rate = Every nth frame is chosen\n",
    "- percent = length of the video summary\n",
    "- skim length = length of sequences of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate=6#3\n",
    "percent=100\n",
    "skim_length=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the video using OpenCV. Calculate the length of the skim based on the number of frames per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=cv2.VideoCapture(r'Air_Force_One.mp4')\n",
    "fps=int(video.get(cv2.CAP_PROP_FPS))\n",
    "frame_count=int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "skim_frames_length=fps*skim_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the required frames and store it into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "i=0\n",
    "while(video.isOpened()):\n",
    "    if i%sampling_rate==0:\n",
    "        video.set(1,i)\n",
    "        ret, frame = video.read()\n",
    "        if frame is None :\n",
    "            break\n",
    "        frames.append(np.asarray(frame))\n",
    "    i+=1\n",
    "frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of video\",frames.shape)\n",
    "rows,cols = frames.shape[1],frames.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retreive the required features using OpenCV Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_hist(frames_raw, num_bins):\n",
    "    print (\"Generate linear Histrograms using OpenCV\")\n",
    "    num_channels=3\n",
    "    histogram=[]\n",
    "    \n",
    "    for frame in frames_raw:\n",
    "        feature_value=[cv2.calcHist([frame],[i],None,[int(num_bins)],[0,256]) for i in num_channels)]\n",
    "        histogram.append(np.asarray(feature_value).flatten())\n",
    "    histogram=np.asarray(histogram)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of centroids. Apply KMeans clustering on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=get_color_hist(frames,16)\n",
    "print(\"Shape of features: \",features.shape)\n",
    "\n",
    "# Choosing number of centers for clustering\n",
    "num_centroids=int(percent*frame_count/skim_frames_length/100)+1\n",
    "print(\"Number of clusters: \"+str(num_centroids))\n",
    "kmeans=KMeans(n_clusters=num_centroids).fit(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all the relevant frames from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centres=[]\n",
    "features_transform=kmeans.transform(features)\n",
    "for cluster in range(features_transform.shape[1]):\n",
    "    centres.append(np.argmin(features_transform.T[cluster]))\n",
    "\n",
    "centres=sorted(centres)\n",
    "frames_indices=[]\n",
    "for centre in centres:\n",
    "    for idx in range(max(int(centre*sampling_rate-skim_frames_length/2),0),min(int(centre*sampling_rate+skim_frames_length/2)+1,frame_count)):\n",
    "        frames_indices.append(idx)\n",
    "frames_indices=sorted(set(frames_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter('afo_out.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 30, (cols,rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while(video.isOpened()):\n",
    "    if i >max(frames_indices):\n",
    "        out.release()\n",
    "        video.release()\n",
    "    if i in frames_indices:\n",
    "        ret, frame = video.read()\n",
    "        if frame is None :\n",
    "            break\n",
    "        out.write(frame)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
